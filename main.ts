import { App, Plugin, PluginSettingTab, Setting, Notice, requestUrl } from 'obsidian';

interface VoiceNotesSettings {
	openaiApiKey: string;
	enableTranscription: boolean;
}

const DEFAULT_SETTINGS: VoiceNotesSettings = {
	openaiApiKey: '',
	enableTranscription: false,
};

// ç®€åŒ–çš„å½•éŸ³çŠ¶æ€ç®¡ç†
class RecordingState {
	isRecording: boolean = false;
	mediaRecorder: MediaRecorder | null = null;
	stream: MediaStream | null = null;
	audioChunks: Blob[] = [];
	startTime: number = 0;
	mimeType: string = 'audio/webm';
}

// è®¾ç½®é¡µé¢
class VoiceNotesSettingTab extends PluginSettingTab {
	plugin: VoiceNotesPlugin;

	constructor(app: App, plugin: VoiceNotesPlugin) {
		super(app, plugin);
		this.plugin = plugin;
	}

	display(): void {
		const { containerEl } = this;
		containerEl.empty();

		containerEl.createEl('h2', { text: 'VoiceNotes è®¾ç½®' });

		// OpenAI API Key è®¾ç½®
		new Setting(containerEl)
			.setName('OpenAI API Key')
			.setDesc('è¯·è¾“å…¥æ‚¨çš„ OpenAI API Key')
			.addText(text => text
				.setPlaceholder('sk-...')
				.setValue(this.plugin.settings.openaiApiKey)
				.onChange(async (value) => {
					this.plugin.settings.openaiApiKey = value;
					await this.plugin.saveSettings();
				}));

		// å¯ç”¨è½¬å½•è®¾ç½®
		new Setting(containerEl)
			.setName('å¯ç”¨è¯­éŸ³è½¬å½•')
			.setDesc('å¼€å¯åå°†ä½¿ç”¨ OpenAI Whisper API è‡ªåŠ¨è½¬å½•å½•éŸ³å†…å®¹')
			.addToggle(toggle => toggle
				.setValue(this.plugin.settings.enableTranscription)
				.onChange(async (value) => {
					this.plugin.settings.enableTranscription = value;
					await this.plugin.saveSettings();
				}));
	}
}

export default class VoiceNotesPlugin extends Plugin {
	settings: VoiceNotesSettings;
	recordingState: RecordingState = new RecordingState();
	statusBarItem: HTMLElement | null = null;

	async onload() {
		await this.loadSettings();

		// åˆ›å»ºçŠ¶æ€æ é¡¹ç›®
		this.statusBarItem = this.addStatusBarItem();
		this.statusBarItem.setText('ğŸ¤ VoiceNotes');
		this.statusBarItem.style.cursor = 'pointer';
		this.statusBarItem.addEventListener('click', () => {
			this.toggleRecording();
		});

		// æ·»åŠ åŠŸèƒ½åŒºå›¾æ ‡
		this.addRibbonIcon('microphone', 'VoiceNotes: å½•éŸ³', () => {
			this.toggleRecording();
		});

		// æ·»åŠ å‘½ä»¤
		this.addCommand({
			id: 'toggle-recording',
			name: 'å¼€å§‹/åœæ­¢å½•éŸ³',
			callback: () => {
				this.toggleRecording();
			}
		});

		// æ·»åŠ è®¾ç½®é¡µé¢
		this.addSettingTab(new VoiceNotesSettingTab(this.app, this));
	}

	onunload() {
		if (this.recordingState.isRecording) {
			this.stopRecording();
		}
	}

	async loadSettings() {
		this.settings = Object.assign({}, DEFAULT_SETTINGS, await this.loadData());
	}

	async saveSettings() {
		await this.saveData(this.settings);
	}

	toggleRecording() {
		if (this.recordingState.isRecording) {
			this.stopRecording();
		} else {
			this.startRecording();
		}
	}

	async startRecording() {
		if (this.recordingState.isRecording) {
			new Notice('å·²ç»åœ¨å½•éŸ³ä¸­...');
			return;
		}

		try {
			// è·å–éº¦å…‹é£æƒé™
			const stream = await navigator.mediaDevices.getUserMedia({ 
				audio: {
					echoCancellation: false,
					noiseSuppression: false,
					autoGainControl: false,
					sampleRate: 44100,
					channelCount: 1
				} 
			});

			// æ£€æµ‹æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
			const formatOptions = [
				{ mimeType: 'audio/webm;codecs=opus', ext: '.webm' },
				{ mimeType: 'audio/webm', ext: '.webm' },
				{ mimeType: 'audio/mpeg', ext: '.mp3' },
				{ mimeType: 'audio/wav', ext: '.wav' },
				{ mimeType: 'audio/ogg;codecs=opus', ext: '.ogg' }
			];

			let selectedFormat = { mimeType: 'audio/webm', ext: '.webm' };
			for (const format of formatOptions) {
				if (MediaRecorder.isTypeSupported(format.mimeType)) {
					selectedFormat = format;
					break;
				}
			}

			// åˆå§‹åŒ–å½•éŸ³çŠ¶æ€
			this.recordingState = new RecordingState();
			this.recordingState.isRecording = true;
			this.recordingState.startTime = Date.now();
			this.recordingState.stream = stream;
			this.recordingState.mimeType = selectedFormat.mimeType;

			// åˆ›å»º MediaRecorder
			this.recordingState.mediaRecorder = new MediaRecorder(stream, {
				mimeType: selectedFormat.mimeType,
				audioBitsPerSecond: 64000
			});

			// æ”¶é›†éŸ³é¢‘æ•°æ®
			this.recordingState.mediaRecorder.ondataavailable = (event) => {
				if (event.data && event.data.size > 0) {
					this.recordingState.audioChunks.push(event.data);
				}
			};

			// å½•éŸ³åœæ­¢æ—¶çš„å¤„ç†
			this.recordingState.mediaRecorder.onstop = () => {
				this.processRecording();
			};

			// å¼€å§‹å½•éŸ³
			this.recordingState.mediaRecorder.start(1000);
			
			// æ›´æ–°çŠ¶æ€æ 
			this.updateStatusBar();
			new Notice('ğŸ”´ å¼€å§‹å½•éŸ³...');

		} catch (error) {
			console.error('å½•éŸ³å¯åŠ¨å¤±è´¥:', error);
			new Notice(`æ— æ³•è®¿é—®éº¦å…‹é£: ${error.message}`);
		}
	}

	stopRecording() {
		if (!this.recordingState.isRecording) {
			return;
		}

		this.recordingState.isRecording = false;

		// åœæ­¢å½•éŸ³
		if (this.recordingState.mediaRecorder) {
			this.recordingState.mediaRecorder.stop();
		}

		// æ¸…ç†éŸ³é¢‘æµ
		if (this.recordingState.stream) {
			this.recordingState.stream.getTracks().forEach(track => track.stop());
		}

		// æ›´æ–°çŠ¶æ€æ 
		this.statusBarItem?.setText('ğŸ¤ VoiceNotes');
		new Notice('ğŸ›‘ å½•éŸ³å·²åœæ­¢');
	}

	async processRecording() {
		if (this.recordingState.audioChunks.length === 0) {
			new Notice('âŒ å½•éŸ³æ•°æ®ä¸ºç©º');
			return;
		}

		// åˆ›å»ºéŸ³é¢‘æ–‡ä»¶
		const audioBlob = new Blob(this.recordingState.audioChunks, { 
			type: this.recordingState.mimeType 
		});

		// 1. ä¿å­˜éŸ³é¢‘æ–‡ä»¶åˆ°ç¬”è®°
		const audioLink = await this.saveAudioFile(audioBlob);
		if (audioLink) {
			this.insertTextToEditor(`### è¯­éŸ³ç¬”è®°\n${audioLink}\n\n`);
		}

		// 2. å¦‚æœå¯ç”¨äº†è½¬å½•ï¼Œåˆ™è¿›è¡Œè½¬å½•
		if (this.settings.enableTranscription && this.settings.openaiApiKey) {
			new Notice('ğŸ”„ æ­£åœ¨è½¬å½•...');
			try {
				const transcription = await this.transcribeAudio(audioBlob);
				if (transcription) {
					this.insertTextToEditor(`**è½¬å½•å†…å®¹:**\n${transcription}\n\n`);
					new Notice('âœ… è½¬å½•å®Œæˆ');
				}
			} catch (error) {
				console.error('è½¬å½•å¤±è´¥:', error);
				new Notice(`âŒ è½¬å½•å¤±è´¥: ${error.message}`);
			}
		}

		// æ¸…ç†çŠ¶æ€
		this.recordingState.audioChunks = [];
	}

	async saveAudioFile(audioBlob: Blob): Promise<string | null> {
		try {
			// ç¡®å®šæ–‡ä»¶æ‰©å±•å
			let extension = '.webm';
			if (audioBlob.type.includes('webm')) extension = '.webm';
			else if (audioBlob.type.includes('mp3') || audioBlob.type.includes('mpeg')) extension = '.mp3';
			else if (audioBlob.type.includes('wav')) extension = '.wav';
			else if (audioBlob.type.includes('ogg')) extension = '.ogg';

			// ç”Ÿæˆæ–‡ä»¶å
			const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
			const filename = `voice-note-${timestamp}${extension}`;

			// è·å–å½“å‰æ–‡ä»¶çš„ç›®å½•
			let folderPath = '';
			const activeFile = this.app.workspace.getActiveFile();
			if (activeFile) {
				folderPath = activeFile.parent?.path || '';
			}

			// æ„å»ºå®Œæ•´è·¯å¾„
			const audioFilePath = folderPath ? `${folderPath}/${filename}` : filename;

			// ä¿å­˜æ–‡ä»¶
			const arrayBuffer = await audioBlob.arrayBuffer();
			await this.app.vault.createBinary(audioFilePath, arrayBuffer);

			// è¿”å› markdown é“¾æ¥
			return `![${filename}](${audioFilePath})`;

		} catch (error) {
			console.error('ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥:', error);
			new Notice(`âŒ ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥: ${error.message}`);
			return null;
		}
	}

	async transcribeAudio(audioBlob: Blob): Promise<string> {
		if (!this.settings.openaiApiKey) {
			throw new Error('OpenAI API Key æœªé…ç½®');
		}

		// åˆ›å»ºå¤šéƒ¨åˆ†è¡¨å•æ•°æ®è¾¹ç•Œ
		const boundary = '----formdata-obsidian-' + Math.random().toString(36);
		
		// ç¡®å®šæ–‡ä»¶å
		let filename = 'audio.webm';
		if (audioBlob.type.includes('webm')) filename = 'audio.webm';
		else if (audioBlob.type.includes('mp3') || audioBlob.type.includes('mpeg')) filename = 'audio.mp3';
		else if (audioBlob.type.includes('wav')) filename = 'audio.wav';
		else if (audioBlob.type.includes('ogg')) filename = 'audio.ogg';

		// æ‰‹åŠ¨æ„å»ºå¤šéƒ¨åˆ†è¡¨å•æ•°æ®
		const audioArrayBuffer = await audioBlob.arrayBuffer();
		const audioBytes = new Uint8Array(audioArrayBuffer);
		
		const textEncoder = new TextEncoder();
		const formParts: Uint8Array[] = [];
		
		// æ·»åŠ æ–‡ä»¶å­—æ®µ
		formParts.push(textEncoder.encode(`--${boundary}\r\n`));
		formParts.push(textEncoder.encode(`Content-Disposition: form-data; name="file"; filename="${filename}"\r\n`));
		formParts.push(textEncoder.encode(`Content-Type: ${audioBlob.type}\r\n\r\n`));
		formParts.push(audioBytes);
		formParts.push(textEncoder.encode('\r\n'));
		
		// æ·»åŠ æ¨¡å‹å­—æ®µ
		formParts.push(textEncoder.encode(`--${boundary}\r\n`));
		formParts.push(textEncoder.encode(`Content-Disposition: form-data; name="model"\r\n\r\n`));
		formParts.push(textEncoder.encode('whisper-1\r\n'));
		
		// æ·»åŠ è¯­è¨€å­—æ®µ
		formParts.push(textEncoder.encode(`--${boundary}\r\n`));
		formParts.push(textEncoder.encode(`Content-Disposition: form-data; name="language"\r\n\r\n`));
		formParts.push(textEncoder.encode('zh\r\n'));
		
		// ç»“æŸè¾¹ç•Œ
		formParts.push(textEncoder.encode(`--${boundary}--\r\n`));
		
		// è®¡ç®—æ€»é•¿åº¦å¹¶åˆå¹¶æ‰€æœ‰éƒ¨åˆ†
		const totalLength = formParts.reduce((sum, part) => sum + part.length, 0);
		const formDataBuffer = new Uint8Array(totalLength);
		let offset = 0;
		for (const part of formParts) {
			formDataBuffer.set(part, offset);
			offset += part.length;
		}

		// ä½¿ç”¨ Obsidian çš„ requestUrl æ–¹æ³•å‘é€è¯·æ±‚
		try {
			const response = await requestUrl({
				url: 'https://api.openai.com/v1/audio/transcriptions',
				method: 'POST',
				headers: {
					'Authorization': `Bearer ${this.settings.openaiApiKey}`,
					'Content-Type': `multipart/form-data; boundary=${boundary}`
				},
				body: formDataBuffer.buffer
			});

			if (response.json && response.json.text) {
				return response.json.text.trim();
			} else {
				throw new Error('è½¬å½•ç»“æœæ ¼å¼æ— æ•ˆ');
			}

		} catch (error) {
			console.error('OpenAI API é”™è¯¯:', error);
			
			// å¤„ç†ä¸åŒç±»å‹çš„é”™è¯¯
			let errorMessage = 'è½¬å½•å¤±è´¥';
			if (error.status === 401) {
				errorMessage = 'API Key æ— æ•ˆæˆ–æœªæˆæƒ';
			} else if (error.status === 429) {
				errorMessage = 'API è¯·æ±‚é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åé‡è¯•';
			} else if (error.status === 403) {
				errorMessage = 'API è®¿é—®è¢«æ‹’ç»ï¼Œè¯·æ£€æŸ¥ API Key æƒé™';
			} else if (error.message) {
				errorMessage = error.message;
			}
			
			throw new Error(errorMessage);
		}
	}

	insertTextToEditor(text: string) {
		if (!text || text.trim() === '') {
			return;
		}

		const activeLeaf = this.app.workspace.activeLeaf;
		if (!activeLeaf) {
			new Notice('âŒ æ²¡æœ‰æ´»è·ƒçš„ç¬”è®°é¡µé¢');
			return;
		}

		const view = activeLeaf.view;
		if (view.getViewType() !== 'markdown') {
			new Notice('âŒ å½“å‰é¡µé¢ä¸æ˜¯ Markdown ç¬”è®°');
			return;
		}

		const editor = (view as any).editor;
		if (!editor) {
			new Notice('âŒ æ— æ³•æ‰¾åˆ°ç¼–è¾‘å™¨');
			return;
		}

		try {
			const cursor = editor.getCursor();
			const textToInsert = text.trim() + '\n';
			editor.replaceRange(textToInsert, cursor);
			editor.setCursor(cursor.line + textToInsert.split('\n').length - 1, 0);
		} catch (error) {
			console.error('æ’å…¥æ–‡æœ¬å¤±è´¥:', error);
			new Notice(`âŒ æ’å…¥æ–‡æœ¬å¤±è´¥: ${error.message}`);
		}
	}

	updateStatusBar() {
		if (!this.statusBarItem) return;

		if (this.recordingState.isRecording) {
			const duration = Math.floor((Date.now() - this.recordingState.startTime) / 1000);
			this.statusBarItem.setText(`ğŸ”´ å½•éŸ³ä¸­ ${duration}s`);
			
			// æ¯ç§’æ›´æ–°ä¸€æ¬¡
			setTimeout(() => {
				if (this.recordingState.isRecording) {
					this.updateStatusBar();
				}
			}, 1000);
		} else {
			this.statusBarItem.setText('ğŸ¤ VoiceNotes');
		}
	}
}
